{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:56:03.371547Z","iopub.execute_input":"2023-11-02T09:56:03.371906Z","iopub.status.idle":"2023-11-02T09:56:03.382003Z","shell.execute_reply.started":"2023-11-02T09:56:03.371879Z","shell.execute_reply":"2023-11-02T09:56:03.381189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -q -U accelerate==0.23.0 bitsandbytes==0.41.1 transformers==4.34.1","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:56:03.383283Z","iopub.execute_input":"2023-11-02T09:56:03.383566Z","iopub.status.idle":"2023-11-02T09:56:29.975507Z","shell.execute_reply.started":"2023-11-02T09:56:03.383543Z","shell.execute_reply":"2023-11-02T09:56:29.974282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport math\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom scipy.stats import entropy\ntrain = pd.read_csv(\"../input/h2oai-predict-the-llm/train.csv\")\ntest = pd.read_csv(\"../input/h2oai-predict-the-llm/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:56:29.977378Z","iopub.execute_input":"2023-11-02T09:56:29.977691Z","iopub.status.idle":"2023-11-02T09:56:35.183460Z","shell.execute_reply.started":"2023-11-02T09:56:29.977661Z","shell.execute_reply":"2023-11-02T09:56:35.182654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"/kaggle/input/llama-2/pytorch/7b-hf/1\"\nmodel_name = \"7b-hf\"\nrandom_seed = 25\ntemperature = 0.0\ndevice_map = {\"\": 0}","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:56:35.184582Z","iopub.execute_input":"2023-11-02T09:56:35.184905Z","iopub.status.idle":"2023-11-02T09:56:35.189688Z","shell.execute_reply.started":"2023-11-02T09:56:35.184878Z","shell.execute_reply":"2023-11-02T09:56:35.188613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/h2oai-predict-the-llm/train.csv\")\ntest = pd.read_csv(\"../input/h2oai-predict-the-llm/test.csv\")\n\ntrain = train.reset_index().rename({\"index\":\"id\"}, axis=1)\n\ntrain.fillna(\" \",inplace=True)\ntest.fillna(\" \",inplace=True)\n\nnp.random.seed(random_seed)\nsalt = \"kappa\"\ntrain[\"group_id\"] = train.Question.apply(lambda x: hash(x + salt) % 1_000_000)\ntest[\"group_id\"] = test.Question.apply(lambda x: hash(x + salt) % 1_000_000)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:56:35.192389Z","iopub.execute_input":"2023-11-02T09:56:35.193003Z","iopub.status.idle":"2023-11-02T09:56:36.556006Z","shell.execute_reply.started":"2023-11-02T09:56:35.192968Z","shell.execute_reply":"2023-11-02T09:56:36.555041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=\"float16\"\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_path,\n                                             quantization_config=bnb_config,\n                                             use_cache = False, \n                                             device_map=device_map)\n\ntokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:56:36.557065Z","iopub.execute_input":"2023-11-02T09:56:36.557319Z","iopub.status.idle":"2023-11-02T09:59:06.637916Z","shell.execute_reply.started":"2023-11-02T09:56:36.557296Z","shell.execute_reply":"2023-11-02T09:59:06.636990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:59:06.639162Z","iopub.execute_input":"2023-11-02T09:59:06.639708Z","iopub.status.idle":"2023-11-02T09:59:06.655026Z","shell.execute_reply.started":"2023-11-02T09:59:06.639679Z","shell.execute_reply":"2023-11-02T09:59:06.654082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(prompt, answer, model):\n\n    # Convert the prompt and answer to PyTorch tensors.\n    input_ids = tokenizer(answer)\n    output_ids = tokenizer(answer)\n\n    # Pad the tensors to the same length as the longest one.\n    input_tokens = len(input_ids.input_ids)\n    output_tokens = len(output_ids.input_ids)\n    max_length = max(input_tokens, output_tokens)\n    input_ids = tokenizer.pad(input_ids, padding='max_length', max_length=max_length, return_tensors=\"pt\").input_ids.reshape((1, -1))\n    output_ids = tokenizer.pad(output_ids, padding='max_length', max_length=max_length, return_tensors=\"pt\").input_ids.reshape((1, -1))\n\n    # Call the model to generate predictions for the prompt.\n    outputs = model(input_ids, labels=output_ids)\n\n    # Extract the loss and logits tensors from the model's output.\n    loss = outputs.loss\n    probs = outputs.logits.softmax(-1)\n    ids = output_ids.tolist()[0][1:]\n\n    # Calculate the cross-entropy loss using the logits tensor.\n    tokens = []\n    logprobs = []\n    l = 0\n    val_ids = 0\n    for i, id in enumerate(ids):\n        p = probs[0,i,id].item()\n        token = tokenizer.decode(id)\n        tokens.append(token)\n        logprob = math.log(p)\n        logprobs.append(logprob)\n        if token != '</s>':\n            l -= logprob\n            val_ids += 1\n\n    # Calculate the estimated loss.\n    estimated_loss = l / val_ids\n    mean_lowest25 = np.mean(sorted(logprobs)[:25])\n    mean_highest25 = np.mean(sorted(logprobs)[-25:])\n    maxp = np.max(logprobs)\n    minp = np.min(logprobs)\n    rangep = maxp - minp\n    meanp = np.mean(logprobs)\n    stdp = np.std(logprobs)\n    entropyp = entropy(np.exp(logprobs))\n    if stdp != 0:\n        kurtosisp = np.mean((logprobs - meanp)**4) / stdp ** 4\n        skewnessp = np.mean((logprobs - meanp)**3) / stdp ** 3\n    else:\n        kurtosisp = 0\n        skewnessp = 0\n    perplexityp = np.exp(-np.mean(logprobs))\n\n    return [\n        estimated_loss,\n        mean_lowest25,\n        mean_highest25,\n        maxp,\n        minp,\n        rangep,\n        meanp,\n        stdp,\n        entropyp,\n        kurtosisp,\n        skewnessp,\n        perplexityp,\n    ]","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:59:06.656394Z","iopub.execute_input":"2023-11-02T09:59:06.656730Z","iopub.status.idle":"2023-11-02T09:59:06.671257Z","shell.execute_reply.started":"2023-11-02T09:59:06.656703Z","shell.execute_reply":"2023-11-02T09:59:06.670252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_features(df, model, model_name):\n\n    new_df = list()\n    base_features = [\"estimated_loss\", \"mean_lowest25\", \"mean_highest25\", \"max\", \"min\", \"range\", \"mean\", \"std\", \"entropy\", \"kurtosis\", \"skewness\", \"perplexity\"]\n    df_features = [f\"{model_name}_{item}\" for item in base_features]\n\n    for i in tqdm(range(len(df))):\n        prompt = df.Question.iloc[i]\n        answer = df.Response.iloc[i]\n        new_df.append(extract_features(prompt, answer, model))\n\n    new_df = pd.DataFrame(new_df, columns=df_features)\n    return new_df\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:59:06.672683Z","iopub.execute_input":"2023-11-02T09:59:06.673529Z","iopub.status.idle":"2023-11-02T09:59:06.683677Z","shell.execute_reply.started":"2023-11-02T09:59:06.673496Z","shell.execute_reply":"2023-11-02T09:59:06.682905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logprob_train = compute_features(train, model, model_name)\nlogprob_test = compute_features(test, model, model_name)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:59:06.684641Z","iopub.execute_input":"2023-11-02T09:59:06.684983Z","iopub.status.idle":"2023-11-02T10:00:18.120493Z","shell.execute_reply.started":"2023-11-02T09:59:06.684958Z","shell.execute_reply":"2023-11-02T10:00:18.118780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logprob_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:00:18.121302Z","iopub.status.idle":"2023-11-02T10:00:18.121661Z","shell.execute_reply.started":"2023-11-02T10:00:18.121474Z","shell.execute_reply":"2023-11-02T10:00:18.121490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logprob_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:00:18.123258Z","iopub.status.idle":"2023-11-02T10:00:18.123639Z","shell.execute_reply.started":"2023-11-02T10:00:18.123442Z","shell.execute_reply":"2023-11-02T10:00:18.123459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logprob_train.to_csv(f\"{model_name}_logprob_train.csv\", index=False)\nlogprob_test.to_csv(f\"{model_name}logprob_test.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:00:18.125291Z","iopub.status.idle":"2023-11-02T10:00:18.125760Z","shell.execute_reply.started":"2023-11-02T10:00:18.125513Z","shell.execute_reply":"2023-11-02T10:00:18.125534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}